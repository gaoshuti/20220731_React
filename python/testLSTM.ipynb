{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09d27c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T02:00:29.369742Z",
     "start_time": "2022-07-26T01:55:22.372191Z"
    },
    "code_folding": [
     67,
     101,
     114,
     124,
     134,
     157,
     212,
     265,
     312,
     318
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_shape:(1701, 1)\n",
      "训练集长度：1701\n",
      "测试集长度：244\n",
      "x_test_shape：(224, 20)\n",
      "x_train: [[[0.25048496]\n",
      "  [0.63754422]\n",
      "  [0.846379  ]\n",
      "  ...\n",
      "  [0.21367574]\n",
      "  [0.18458396]\n",
      "  [0.34618782]]\n",
      "\n",
      " [[0.53855787]\n",
      "  [0.50497691]\n",
      "  [0.4428279 ]\n",
      "  ...\n",
      "  [0.46261862]\n",
      "  [0.49354821]\n",
      "  [0.53602013]]\n",
      "\n",
      " [[0.55091812]\n",
      "  [0.64072099]\n",
      "  [0.45723467]\n",
      "  ...\n",
      "  [0.50684888]\n",
      "  [0.59170407]\n",
      "  [0.53697785]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.469999  ]\n",
      "  [0.47615977]\n",
      "  [0.45385034]\n",
      "  ...\n",
      "  [0.52503677]\n",
      "  [0.59724305]\n",
      "  [0.57297394]]\n",
      "\n",
      " [[0.52827754]\n",
      "  [0.24516438]\n",
      "  [0.81866334]\n",
      "  ...\n",
      "  [0.76365823]\n",
      "  [0.50460867]\n",
      "  [0.50931708]]\n",
      "\n",
      " [[0.48000633]\n",
      "  [0.63085919]\n",
      "  [0.34464373]\n",
      "  ...\n",
      "  [0.37675037]\n",
      "  [0.37210411]\n",
      "  [0.50759025]]]\n",
      "y_train: [0.03032265 0.62738585 0.62120985 ... 0.34657726 0.79418584 0.65603542]\n",
      "x_test: [[[0.54408008]\n",
      "  [0.55578839]\n",
      "  [0.50847123]\n",
      "  ...\n",
      "  [0.58656411]\n",
      "  [0.46221662]\n",
      "  [0.44742619]]\n",
      "\n",
      " [[0.55578839]\n",
      "  [0.50847123]\n",
      "  [0.48463451]\n",
      "  ...\n",
      "  [0.46221662]\n",
      "  [0.44742619]\n",
      "  [0.49997637]]\n",
      "\n",
      " [[0.50847123]\n",
      "  [0.48463451]\n",
      "  [0.49820883]\n",
      "  ...\n",
      "  [0.44742619]\n",
      "  [0.49997637]\n",
      "  [0.50807082]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.57584189]\n",
      "  [0.34896462]\n",
      "  [0.54649406]\n",
      "  ...\n",
      "  [0.50968022]\n",
      "  [0.61881637]\n",
      "  [0.55589033]]\n",
      "\n",
      " [[0.34896462]\n",
      "  [0.54649406]\n",
      "  [0.66511017]\n",
      "  ...\n",
      "  [0.61881637]\n",
      "  [0.55589033]\n",
      "  [0.46246494]]\n",
      "\n",
      " [[0.54649406]\n",
      "  [0.66511017]\n",
      "  [0.52110194]\n",
      "  ...\n",
      "  [0.55589033]\n",
      "  [0.46246494]\n",
      "  [0.36046063]]]\n",
      "y_test: [0.49997637 0.50807082 0.25660414 0.28763321 0.50239665 0.44480206\n",
      " 0.12964721 0.57184541 0.60689648 0.35490602 0.64152059 0.42660236\n",
      " 0.4268878  0.64862827 0.58157708 0.69650004 0.60740017 0.4217917\n",
      " 0.62339364 0.48249837 0.66685197 0.56839381 0.54172437 0.62250253\n",
      " 0.57360467 0.56329477 0.437619   0.45086398 0.33407892 0.5036515\n",
      " 0.6245607  0.5456438  0.56750786 0.65053703 0.15623612 0.62297021\n",
      " 0.6817396  0.55568707 0.60913867 0.62627339 0.57337302 0.47071549\n",
      " 0.45488634 0.51378421 0.46817695 0.64707854 0.46112087 0.50089966\n",
      " 0.41152236 0.36473708 0.53128434 0.4865498  0.30355602 0.48903277\n",
      " 0.67602217 0.54950995 0.29705465 0.46675111 0.45974008 0.60171677\n",
      " 0.45692809 0.60886715 0.58067623 0.53280441 0.54703219 0.42900651\n",
      " 0.40842438 0.61229357 0.50655225 0.61439952 0.54016035 0.6104442\n",
      " 0.58236149 0.41542531 0.5158059  0.49029571 0.44413302 0.42286048\n",
      " 0.17025081 0.58787553 0.4430997  0.52639305 0.63302237 0.62248414\n",
      " 0.45267275 0.5154681  0.55675972 0.56768916 0.36587599 0.51604719\n",
      " 0.2761752  0.04867622 0.52533343 0.26253026 0.55397153 0.52652228\n",
      " 0.60878564 0.51947557 0.40852788 0.65748661 0.439023   0.62226539\n",
      " 0.40674406 0.3571937  0.55167114 0.59119666 0.60229477 0.33902978\n",
      " 0.62680923 0.47977106 0.49740245 0.51144372 0.46593553 0.42458923\n",
      " 0.5046421  0.53548561 0.62305725 0.4772481  0.40962028 0.44329252\n",
      " 0.40644917 0.52920561 0.39522591 0.28307836 0.39711724 0.39356468\n",
      " 0.64487019 0.3603856  0.64601134 0.58194163 0.53859103 0.57283063\n",
      " 0.38439277 0.4252911  0.41994709 0.57449136 0.54253207 0.43316982\n",
      " 0.5274801  0.43552199 0.61625374 0.69664238 0.47380125 0.39163232\n",
      " 0.45014877 0.49351119 0.54963988 0.45998991 0.53665935 0.48041486\n",
      " 0.33162557 0.55564515 0.5331461  0.59549965 0.40393169 0.43537484\n",
      " 0.57104761 0.52794411 0.44650257 0.57177225 0.59093625 0.50571986\n",
      " 0.40811489 0.54272237 0.29517859 0.56067266 0.60362873 0.05841413\n",
      " 0.45090115 0.45948672 0.45071937 0.62358463 0.36002877 0.65596821\n",
      " 0.7541935  0.44882947 0.48162833 0.3889367  0.50952059 0.47675735\n",
      " 0.53899895 0.62694078 0.6071932  0.6498621  0.54287218 0.38840866\n",
      " 0.57807652 0.47847861 0.51072685 0.65103413 0.58937345 0.53174086\n",
      " 0.71638579 0.58533898 0.53843109 0.35368991 0.5542131  0.48124104\n",
      " 0.24126332 0.4786094  0.56770829 0.57584189 0.34896462 0.54649406\n",
      " 0.66511017 0.52110194 0.48226878 0.41750726 0.51804151 0.39174061\n",
      " 0.55852254 0.55306911 0.52539843 0.31906577 0.56358723 0.48434761\n",
      " 0.44322282 0.54459335 0.50968022 0.61881637 0.55589033 0.46246494\n",
      " 0.36046063 0.59295961]\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 7s 90ms/step - loss: 0.0428 - val_loss: 0.0139\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0177 - val_loss: 0.0140\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0176 - val_loss: 0.0139\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0175 - val_loss: 0.0136\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0176 - val_loss: 0.0137\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0175 - val_loss: 0.0138\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0175 - val_loss: 0.0135\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 0.0171 - val_loss: 0.0138\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 0.0174 - val_loss: 0.0136\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0176 - val_loss: 0.0140\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0173 - val_loss: 0.0134\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0166 - val_loss: 0.0134\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0167 - val_loss: 0.0142\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0168 - val_loss: 0.0134\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0179 - val_loss: 0.0134\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0173 - val_loss: 0.0133\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0173 - val_loss: 0.0136\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0169 - val_loss: 0.0137\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0171 - val_loss: 0.0147\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0169 - val_loss: 0.0136\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0168 - val_loss: 0.0135\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0169 - val_loss: 0.0138\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 2s 75ms/step - loss: 0.0170 - val_loss: 0.0132\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 0.0166 - val_loss: 0.0134\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 2s 75ms/step - loss: 0.0178 - val_loss: 0.0133\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 2s 66ms/step - loss: 0.0176 - val_loss: 0.0140\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.0169 - val_loss: 0.0137\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 0.0168 - val_loss: 0.0134\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0172 - val_loss: 0.0137\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0166 - val_loss: 0.0132\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0166 - val_loss: 0.0135\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0168 - val_loss: 0.0135\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0168 - val_loss: 0.0134\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 0.0166 - val_loss: 0.0132\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0167 - val_loss: 0.0134\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0167 - val_loss: 0.0133\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 0.0165 - val_loss: 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0170 - val_loss: 0.0132\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0166 - val_loss: 0.0132\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0171 - val_loss: 0.0136\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0165 - val_loss: 0.0138\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0166 - val_loss: 0.0133\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0168 - val_loss: 0.0135\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0166 - val_loss: 0.0134\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0170 - val_loss: 0.0132\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0165 - val_loss: 0.0138\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0168 - val_loss: 0.0132\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0166 - val_loss: 0.0132\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0164 - val_loss: 0.0131\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0166 - val_loss: 0.0133\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0166 - val_loss: 0.0134\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0167 - val_loss: 0.0131\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0168 - val_loss: 0.0140\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 0.0172 - val_loss: 0.0140\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0166 - val_loss: 0.0131\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 0.0167 - val_loss: 0.0131\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0166 - val_loss: 0.0132\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0164 - val_loss: 0.0133\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0166 - val_loss: 0.0131\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0162 - val_loss: 0.0131\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0162 - val_loss: 0.0135\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0164 - val_loss: 0.0134\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0163 - val_loss: 0.0137\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0169 - val_loss: 0.0137\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0167 - val_loss: 0.0132\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0165 - val_loss: 0.0131\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0163 - val_loss: 0.0131\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0166 - val_loss: 0.0131\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.0165 - val_loss: 0.0133\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 0.0163 - val_loss: 0.0135\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 0.0166 - val_loss: 0.0143\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0163 - val_loss: 0.0131\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 0.0163 - val_loss: 0.0137\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0164 - val_loss: 0.0134\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 0.0163 - val_loss: 0.0134\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 2s 69ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 2s 69ms/step - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 2s 68ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 2s 68ms/step - loss: 0.0166 - val_loss: 0.0132\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0163 - val_loss: 0.0135\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0164 - val_loss: 0.0131\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 0.0163 - val_loss: 0.0131\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0166 - val_loss: 0.0139\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0163 - val_loss: 0.0135\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 0.0166 - val_loss: 0.0131\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0165 - val_loss: 0.0132\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 2s 65ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 2s 65ms/step - loss: 0.0166 - val_loss: 0.0132\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 2s 55ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0161 - val_loss: 0.0134\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 2s 66ms/step - loss: 0.0163 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0161 - val_loss: 0.0135\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0163 - val_loss: 0.0135\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0163 - val_loss: 0.0134\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0163 - val_loss: 0.0134\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0164 - val_loss: 0.0133\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0165 - val_loss: 0.0133\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 0.0165 - val_loss: 0.0133\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0163 - val_loss: 0.0133\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0159 - val_loss: 0.0134\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0160 - val_loss: 0.0133\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 0.0164 - val_loss: 0.0132\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.0160 - val_loss: 0.0134\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0160 - val_loss: 0.0136\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0161 - val_loss: 0.0135\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0159 - val_loss: 0.0135\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 2s 55ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 0.0159 - val_loss: 0.0135\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0157 - val_loss: 0.0132\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 0.0160 - val_loss: 0.0133\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 0.0161 - val_loss: 0.0132\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0160 - val_loss: 0.0140\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 2s 68ms/step - loss: 0.0163 - val_loss: 0.0132\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 0.0158 - val_loss: 0.0133\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 2s 67ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 0.0162 - val_loss: 0.0132\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 0.0161 - val_loss: 0.0133\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 2s 66ms/step - loss: 0.0160 - val_loss: 0.0133\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0160 - val_loss: 0.0132\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 2s 65ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 0.0158 - val_loss: 0.0135\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 0.0157 - val_loss: 0.0136\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 0.0159 - val_loss: 0.0135\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 2s 68ms/step - loss: 0.0160 - val_loss: 0.0133\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 2s 65ms/step - loss: 0.0158 - val_loss: 0.0134\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 0.0159 - val_loss: 0.0133\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 20, 80)            26240     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 20, 80)            0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_9 (LSTM)               (None, 100)               72400     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 98,741\n",
      "Trainable params: 98,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "loss:[0.04279328137636185, 0.017735090106725693, 0.017583351582288742, 0.017503388226032257, 0.017613761126995087, 0.017469331622123718, 0.017513403668999672, 0.01705973781645298, 0.01740046963095665, 0.01762216165661812, 0.017327668145298958, 0.01655678078532219, 0.01667303964495659, 0.01680813543498516, 0.017853768542408943, 0.01731991209089756, 0.01734028197824955, 0.016944492235779762, 0.017100883647799492, 0.016854826360940933, 0.0167721975594759, 0.016908716410398483, 0.016896331682801247, 0.016943790018558502, 0.01700679399073124, 0.016623107716441154, 0.01781235821545124, 0.0176373403519392, 0.016938766464591026, 0.01684514991939068, 0.017246412113308907, 0.016616888344287872, 0.016618041321635246, 0.016784939914941788, 0.016758283600211143, 0.016460560262203217, 0.01682611182332039, 0.01683608815073967, 0.016603529453277588, 0.016774991527199745, 0.016688544303178787, 0.01666693575680256, 0.016537606716156006, 0.01690473034977913, 0.016975274309515953, 0.016403496265411377, 0.016616646200418472, 0.016831565648317337, 0.017127126455307007, 0.01680085062980652, 0.016464587301015854, 0.016847947612404823, 0.016559597104787827, 0.016817066818475723, 0.01662958227097988, 0.016974229365587234, 0.01652528904378414, 0.016786210238933563, 0.01642802730202675, 0.016585512086749077, 0.016382480040192604, 0.016532868146896362, 0.016573579981923103, 0.016523689031600952, 0.016567612066864967, 0.01670609414577484, 0.016834372654557228, 0.016828181222081184, 0.017151203006505966, 0.01660712994635105, 0.016829216852784157, 0.01670951023697853, 0.01660197786986828, 0.016177063807845116, 0.01639588363468647, 0.01658874750137329, 0.016233477741479874, 0.016186051070690155, 0.01680115796625614, 0.016406001523137093, 0.016340626403689384, 0.016886955127120018, 0.01666375622153282, 0.01634795404970646, 0.01654217205941677, 0.016298655420541763, 0.016334326937794685, 0.01656005159020424, 0.01621018350124359, 0.01651567593216896, 0.016457142308354378, 0.016277628019452095, 0.016399962827563286, 0.016178321093320847, 0.016596922650933266, 0.01632538065314293, 0.016267962753772736, 0.016424881294369698, 0.016273953020572662, 0.0164339616894722, 0.01634884439408779, 0.016216538846492767, 0.016174394637346268, 0.016600381582975388, 0.016327841207385063, 0.016286563128232956, 0.016490252688527107, 0.0163666270673275, 0.01644449681043625, 0.016339700669050217, 0.016304276883602142, 0.016172386705875397, 0.016274329274892807, 0.016373779624700546, 0.016587231308221817, 0.016296150162816048, 0.01657520979642868, 0.01647009328007698, 0.016125263646245003, 0.01659245975315571, 0.01635137014091015, 0.016115451231598854, 0.01605992764234543, 0.016312766820192337, 0.016196615993976593, 0.016061842441558838, 0.016222521662712097, 0.016096172854304314, 0.016172101721167564, 0.01617959514260292, 0.01625058799982071, 0.01610337197780609, 0.016145648434758186, 0.01609158143401146, 0.01626807451248169, 0.01623431406915188, 0.016262538731098175, 0.016114216297864914, 0.016176437959074974, 0.016091369092464447, 0.016131576150655746, 0.016185374930500984, 0.016087330877780914, 0.016274893656373024, 0.01631198264658451, 0.01596771739423275, 0.016376320272684097, 0.016446197405457497, 0.016166863963007927, 0.016079477965831757, 0.016002073884010315, 0.01645471341907978, 0.01635478064417839, 0.016038138419389725, 0.016160449013113976, 0.016527079045772552, 0.016138549894094467, 0.01625404693186283, 0.015978774055838585, 0.01634990982711315, 0.016096120700240135, 0.016053486615419388, 0.015935838222503662, 0.01612832583487034, 0.016028597950935364, 0.01636495254933834, 0.01606958732008934, 0.016075298190116882, 0.01590697653591633, 0.015975819900631905, 0.016032814979553223, 0.016234595328569412, 0.016048649325966835, 0.016095614060759544, 0.01608469896018505, 0.016007523983716965, 0.016170181334018707, 0.01590426079928875, 0.015921857208013535, 0.015905186533927917, 0.015711436048150063, 0.01602134481072426, 0.016053389757871628, 0.016010208055377007, 0.016339946538209915, 0.01580171473324299, 0.01591886579990387, 0.01616630144417286, 0.016063526272773743, 0.015980295836925507, 0.01602344959974289, 0.01593855582177639, 0.0157916396856308, 0.01573910005390644, 0.016231205314397812, 0.015894988551735878, 0.015934456139802933, 0.015968646854162216, 0.01584448106586933, 0.015924036502838135]\n",
      "val_loss:[0.013887420296669006, 0.013967184349894524, 0.01394545380026102, 0.01360707450658083, 0.013654619455337524, 0.013835342600941658, 0.01351831667125225, 0.013782898895442486, 0.013639607466757298, 0.014036986045539379, 0.013417827896773815, 0.013382439501583576, 0.01420754473656416, 0.013388246297836304, 0.013440853916108608, 0.013344122096896172, 0.013634366914629936, 0.013683856464922428, 0.014650934375822544, 0.01355561800301075, 0.013546864502131939, 0.013336849398911, 0.0138178626075387, 0.013295684941112995, 0.013247421011328697, 0.013437829911708832, 0.013310530222952366, 0.014014155603945255, 0.01369599997997284, 0.013375863432884216, 0.013749039731919765, 0.013213803991675377, 0.013502265326678753, 0.013186359778046608, 0.013243813998997211, 0.013234356418251991, 0.013537568971514702, 0.013404108583927155, 0.01318674348294735, 0.013167934492230415, 0.013421005569398403, 0.01327228732407093, 0.013221721164882183, 0.013319900259375572, 0.0131568918004632, 0.013166716322302818, 0.013151220045983791, 0.013226286508142948, 0.013578303158283234, 0.01321586687117815, 0.013779786415398121, 0.013146317563951015, 0.013284103944897652, 0.013514444231987, 0.013363207690417767, 0.013173011131584644, 0.013809978030622005, 0.013230384327471256, 0.01321896817535162, 0.013165696524083614, 0.013138845562934875, 0.01320667378604412, 0.013290947303175926, 0.01316867582499981, 0.013429945334792137, 0.013135948218405247, 0.013124658726155758, 0.014011341147124767, 0.014020045287907124, 0.013123712502419949, 0.01312313973903656, 0.013122722506523132, 0.013201495632529259, 0.01327651459723711, 0.013278977945446968, 0.013125373050570488, 0.013122007250785828, 0.01351423654705286, 0.013137586414813995, 0.013361290097236633, 0.013665130361914635, 0.013682467862963676, 0.013210786506533623, 0.013234831392765045, 0.013117016293108463, 0.01314835250377655, 0.013157563284039497, 0.013121837750077248, 0.01321644801646471, 0.013300291262567043, 0.013174861669540405, 0.01347501389682293, 0.013154715299606323, 0.013349649496376514, 0.014345400035381317, 0.013131752610206604, 0.013716543093323708, 0.01339734811335802, 0.013438825495541096, 0.01319720409810543, 0.01318574883043766, 0.01341371051967144, 0.013264919631183147, 0.013205348514020443, 0.013185419142246246, 0.01347695104777813, 0.013157415203750134, 0.01316695474088192, 0.013146279379725456, 0.013138332404196262, 0.013223068788647652, 0.013154123909771442, 0.013170606456696987, 0.013163721188902855, 0.013918335549533367, 0.013450837694108486, 0.013133427128195763, 0.013225062750279903, 0.013219454325735569, 0.01315337885171175, 0.0131868626922369, 0.01319445762783289, 0.013373068533837795, 0.013321153819561005, 0.013239302672445774, 0.013172807171940804, 0.013207480311393738, 0.01329660415649414, 0.013195297680795193, 0.013290886767208576, 0.013225833885371685, 0.013221492059528828, 0.013221303932368755, 0.013461795635521412, 0.013247333467006683, 0.013205358758568764, 0.01349611021578312, 0.013171711005270481, 0.013282157480716705, 0.013254476711153984, 0.013179120607674122, 0.013195627368986607, 0.013201670721173286, 0.01344501692801714, 0.013411151245236397, 0.013195461593568325, 0.013257388956844807, 0.013178939931094646, 0.013189584016799927, 0.013243669643998146, 0.013584877364337444, 0.01325224433094263, 0.013185283169150352, 0.01318465918302536, 0.01318941731005907, 0.013311228714883327, 0.013221888802945614, 0.013205640949308872, 0.01323196291923523, 0.013252000324428082, 0.013189801946282387, 0.013266921043395996, 0.013416321948170662, 0.013274396769702435, 0.013277111575007439, 0.013216192834079266, 0.01319823507219553, 0.013226781971752644, 0.01332402415573597, 0.013409669511020184, 0.013586067594587803, 0.013216321356594563, 0.013230652548372746, 0.013235830701887608, 0.013520992361009121, 0.013239673338830471, 0.013273914344608784, 0.013496906496584415, 0.01332042645663023, 0.013452972285449505, 0.013191966339945793, 0.01332071702927351, 0.01323345210403204, 0.0139585230499506, 0.013188944198191166, 0.013260667212307453, 0.013312405906617641, 0.013227700255811214, 0.013345854356884956, 0.013310207985341549, 0.013233003206551075, 0.013311806134879589, 0.01346029806882143, 0.013557174243032932, 0.01327538676559925, 0.01349758543074131, 0.013343831524252892, 0.013349608518183231, 0.013430782593786716, 0.01334202941507101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 14ms/step\n",
      "predicted_stock_price: [[0.5052567 ]\n",
      " [0.5088063 ]\n",
      " [0.5094566 ]\n",
      " [0.47772264]\n",
      " [0.47090113]\n",
      " [0.49492365]\n",
      " [0.48925042]\n",
      " [0.44599247]\n",
      " [0.49905068]\n",
      " [0.5100186 ]\n",
      " [0.4707476 ]\n",
      " [0.5131358 ]\n",
      " [0.48150164]\n",
      " [0.48214728]\n",
      " [0.5159013 ]\n",
      " [0.5108583 ]\n",
      " [0.5328101 ]\n",
      " [0.5253314 ]\n",
      " [0.50730574]\n",
      " [0.5300165 ]\n",
      " [0.51726115]\n",
      " [0.54097795]\n",
      " [0.5328462 ]\n",
      " [0.5309928 ]\n",
      " [0.54038125]\n",
      " [0.5367066 ]\n",
      " [0.5360555 ]\n",
      " [0.52090704]\n",
      " [0.5168829 ]\n",
      " [0.4992653 ]\n",
      " [0.5113769 ]\n",
      " [0.52866757]\n",
      " [0.5199307 ]\n",
      " [0.52240866]\n",
      " [0.5340659 ]\n",
      " [0.47855955]\n",
      " [0.51986253]\n",
      " [0.535023  ]\n",
      " [0.522419  ]\n",
      " [0.5305849 ]\n",
      " [0.53490853]\n",
      " [0.531438  ]\n",
      " [0.5205181 ]\n",
      " [0.51583624]\n",
      " [0.5198847 ]\n",
      " [0.51406145]\n",
      " [0.53563106]\n",
      " [0.5144872 ]\n",
      " [0.5163052 ]\n",
      " [0.50300443]\n",
      " [0.49266803]\n",
      " [0.5090238 ]\n",
      " [0.50436884]\n",
      " [0.4795959 ]\n",
      " [0.49669975]\n",
      " [0.5272927 ]\n",
      " [0.51044774]\n",
      " [0.47836232]\n",
      " [0.49244747]\n",
      " [0.4925614 ]\n",
      " [0.51452875]\n",
      " [0.49668878]\n",
      " [0.5180682 ]\n",
      " [0.516613  ]\n",
      " [0.5129378 ]\n",
      " [0.516002  ]\n",
      " [0.50270176]\n",
      " [0.49773386]\n",
      " [0.5222951 ]\n",
      " [0.5121256 ]\n",
      " [0.52719957]\n",
      " [0.5192493 ]\n",
      " [0.52951837]\n",
      " [0.5280732 ]\n",
      " [0.50946486]\n",
      " [0.5170016 ]\n",
      " [0.5138546 ]\n",
      " [0.507282  ]\n",
      " [0.5014866 ]\n",
      " [0.46858573]\n",
      " [0.5097984 ]\n",
      " [0.49414247]\n",
      " [0.5046717 ]\n",
      " [0.5207224 ]\n",
      " [0.52062666]\n",
      " [0.4991718 ]\n",
      " [0.50628805]\n",
      " [0.51323116]\n",
      " [0.51792455]\n",
      " [0.4952373 ]\n",
      " [0.50910175]\n",
      " [0.48094815]\n",
      " [0.44769728]\n",
      " [0.49190187]\n",
      " [0.46201056]\n",
      " [0.5018744 ]\n",
      " [0.49762124]\n",
      " [0.510465  ]\n",
      " [0.4949612 ]\n",
      " [0.47964606]\n",
      " [0.51662403]\n",
      " [0.48998398]\n",
      " [0.5176084 ]\n",
      " [0.4929765 ]\n",
      " [0.48575175]\n",
      " [0.5077358 ]\n",
      " [0.5178312 ]\n",
      " [0.52291095]\n",
      " [0.49157482]\n",
      " [0.5232507 ]\n",
      " [0.50731206]\n",
      " [0.5093981 ]\n",
      " [0.5104275 ]\n",
      " [0.50476754]\n",
      " [0.49797666]\n",
      " [0.50584304]\n",
      " [0.5107161 ]\n",
      " [0.5245939 ]\n",
      " [0.50691015]\n",
      " [0.49698892]\n",
      " [0.49738693]\n",
      " [0.4914299 ]\n",
      " [0.5060903 ]\n",
      " [0.4893055 ]\n",
      " [0.4715336 ]\n",
      " [0.4793156 ]\n",
      " [0.4782501 ]\n",
      " [0.51796126]\n",
      " [0.47542715]\n",
      " [0.5169778 ]\n",
      " [0.50814956]\n",
      " [0.5049345 ]\n",
      " [0.5117199 ]\n",
      " [0.49037698]\n",
      " [0.49295652]\n",
      " [0.49152684]\n",
      " [0.5126344 ]\n",
      " [0.5116439 ]\n",
      " [0.49831218]\n",
      " [0.50838137]\n",
      " [0.4968474 ]\n",
      " [0.5207356 ]\n",
      " [0.53630704]\n",
      " [0.5101571 ]\n",
      " [0.49899474]\n",
      " [0.50110996]\n",
      " [0.50611585]\n",
      " [0.51459265]\n",
      " [0.5040561 ]\n",
      " [0.51252705]\n",
      " [0.5054341 ]\n",
      " [0.48557353]\n",
      " [0.5091735 ]\n",
      " [0.5087991 ]\n",
      " [0.51917386]\n",
      " [0.4947633 ]\n",
      " [0.49519575]\n",
      " [0.5123129 ]\n",
      " [0.5092977 ]\n",
      " [0.49939913]\n",
      " [0.51477194]\n",
      " [0.5199184 ]\n",
      " [0.51109445]\n",
      " [0.49857178]\n",
      " [0.51251125]\n",
      " [0.4835171 ]\n",
      " [0.51065177]\n",
      " [0.52031773]\n",
      " [0.45738634]\n",
      " [0.48520347]\n",
      " [0.48983186]\n",
      " [0.4893085 ]\n",
      " [0.5157838 ]\n",
      " [0.4772705 ]\n",
      " [0.5191779 ]\n",
      " [0.5384127 ]\n",
      " [0.49919358]\n",
      " [0.5039723 ]\n",
      " [0.49232793]\n",
      " [0.50571394]\n",
      " [0.5038225 ]\n",
      " [0.5126847 ]\n",
      " [0.5267564 ]\n",
      " [0.5271184 ]\n",
      " [0.53573763]\n",
      " [0.52492976]\n",
      " [0.5073164 ]\n",
      " [0.52474624]\n",
      " [0.5149279 ]\n",
      " [0.5176421 ]\n",
      " [0.5359168 ]\n",
      " [0.5310612 ]\n",
      " [0.52512014]\n",
      " [0.5492104 ]\n",
      " [0.5367322 ]\n",
      " [0.53296536]\n",
      " [0.5109587 ]\n",
      " [0.525553  ]\n",
      " [0.517933  ]\n",
      " [0.4885664 ]\n",
      " [0.50345725]\n",
      " [0.5165722 ]\n",
      " [0.51936275]\n",
      " [0.48914313]\n",
      " [0.50901663]\n",
      " [0.5284302 ]\n",
      " [0.51114595]\n",
      " [0.5064868 ]\n",
      " [0.49690625]\n",
      " [0.50762105]\n",
      " [0.49270886]\n",
      " [0.5120688 ]\n",
      " [0.51366806]\n",
      " [0.5114181 ]\n",
      " [0.48526815]\n",
      " [0.5106177 ]\n",
      " [0.5026109 ]\n",
      " [0.49712914]\n",
      " [0.5092317 ]\n",
      " [0.5058042 ]\n",
      " [0.52215755]\n",
      " [0.5158495 ]\n",
      " [0.50521827]\n",
      " [0.4908985 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均方误差: 0.000534\n",
      "均方根误差: 0.023110\n",
      "平均绝对误差: 0.017681\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import optimizers\n",
    "from tensorflow.keras import Sequential, callbacks\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CgcpLSTM:\n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        构造函数，初始化模型\n",
    "        :param data_list: 真实数据列表\n",
    "        \"\"\"\n",
    "        # 神经网络名称\n",
    "        self.name = name\n",
    "        self.__file__ = '/Users/rumeng/Downloads/qingzang/LSTM'\n",
    "        # 训练集占总样本的比例\n",
    "        self.train_all_ratio = 0.875\n",
    "        # 连续样本点数\n",
    "        self.continuous_sample_point_num = 20\n",
    "        # 定义归一化：归一化到(0，1)之间\n",
    "        self.sc = MinMaxScaler(feature_range=(0, 1))\n",
    "        # 每次喂入神经网络的样本数\n",
    "        self.batch_size = 64\n",
    "        # 数据集的迭代次数\n",
    "        self.epochs = 200\n",
    "        # 每多少次训练集迭代，验证一次测试集\n",
    "        self.validation_freq = 1\n",
    "        # 配置模型\n",
    "        self.model = Sequential([\n",
    "            # LSTM层（记忆体个数，是否返回输出（True：每个时间步输出ht，False：仅最后时间步输出ht））\n",
    "            # 配置具有80个记忆体的LSTM层，每个时间步输出ht\n",
    "            LSTM(80, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            # 配置具有100个记忆体的LSTM层，仅在最后一步返回ht\n",
    "            LSTM(100),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        # 配置训练方法\n",
    "        # 该应用只观测loss数值，不观测准确率，所以删去metrics选项，一会在每个epoch迭代显示时只显示loss值\n",
    "        self.model.compile(\n",
    "            optimizer=optimizers.Adam(0.001),\n",
    "            loss='mean_squared_error',  # 损失函数用均方误差\n",
    "        )\n",
    "        # 配置断点续训文件\n",
    "        self.checkpoint_save_path = os.path.abspath(\n",
    "            os.path.dirname(self.__file__)) + \"\\\\checkpoint\\\\\" + self.name + \"_LSTM_stock.ckpt\"\n",
    "#         if os.path.exists(self.checkpoint_save_path + '.index'):\n",
    "#             print('-' * 20 + \"加载模型\" + \"-\" * 20)\n",
    "#             self.model.load_weights(self.checkpoint_save_path)\n",
    "\n",
    "        # 断点续训，存储最佳模型\n",
    "        self.cp_callback = callbacks.ModelCheckpoint(filepath=self.checkpoint_save_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     save_best_only=True,\n",
    "                                                     # monitor='val_accuracy',\n",
    "                                                     monitor='val_loss',\n",
    "                                                     )\n",
    "\n",
    "    def make_set(self, data_list):\n",
    "        \"\"\"\n",
    "        使用历史数据制作训练集和测试集\n",
    "        :param data_list: 历史数据列表\n",
    "        :return: train_set, test_set 归一化处理后的训练集合测试集\n",
    "        \"\"\"\n",
    "        # 将历史数据装换为ndarray\n",
    "        if isinstance(data_list, list):\n",
    "            data_array = np.array(data_list)\n",
    "        elif isinstance(data_list, np.ndarray):\n",
    "            data_array = data_list\n",
    "        else:\n",
    "            raise Exception(\"数据源格式错误\")\n",
    "\n",
    "        # 对一维矩阵进行升维操作\n",
    "        if len(data_array.shape) == 1:\n",
    "            data_array = data_array.reshape(data_array.shape[0], 1)\n",
    "\n",
    "        if data_array.shape[1] != 1:\n",
    "            raise Exception(\"数据源形状有误\")\n",
    "\n",
    "        # 按照比例对数据进行分割\n",
    "        index = int(data_array.shape[0] * self.train_all_ratio)\n",
    "        train_set = data_array[:index, :]\n",
    "        test_set = data_array[index:, :]\n",
    "\n",
    "        print(\"train_set_shape:{}\".format(train_set.shape))\n",
    "        # 对训练集和测试集进行归一化处理\n",
    "        train_set, test_set = self.gui_yi(train_set, test_set)\n",
    "\n",
    "        print(\"训练集长度：{}\".format(len(train_set)))\n",
    "        print(\"测试集长度：{}\".format(len(test_set)))\n",
    "        return train_set, test_set\n",
    "\n",
    "    def gui_yi(self, train_set, test_set):\n",
    "        \"\"\"\n",
    "        对训练集合测试集进行归一化处理\n",
    "        :param test_set: 未进行归一化的训练集数据\n",
    "        :param train_set: 未进行归一化处理的测试集数据\n",
    "        :return: train_set, test_set 归一化处理后的训练集合测试集\n",
    "        \"\"\"\n",
    "        # 求得训练集的最大值，最小值这些训练集固有的属性，并在训练集上进行归一化\n",
    "        train_set_scaled = self.sc.fit_transform(train_set)\n",
    "        # 利用训练集的属性对测试集进行归一化\n",
    "        test_set = self.sc.transform(test_set)\n",
    "        return train_set_scaled, test_set\n",
    "\n",
    "    def fan_gui_yi(self, data_set):\n",
    "        \"\"\"\n",
    "        逆归一化\n",
    "        :param data_set: 需要还原的数据\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 对数据进行逆归一化还原\n",
    "        data_set = self.sc.inverse_transform(data_set)\n",
    "        return data_set\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test):\n",
    "        \"\"\"\n",
    "        训练模型\n",
    "        :param x_train:\n",
    "        :param y_train:\n",
    "        :param x_test:\n",
    "        :param y_test:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 训练模型\n",
    "        history = self.model.fit(x_train, y_train,\n",
    "                                 # 每次喂入神经网络的样本数\n",
    "                                 batch_size=self.batch_size,\n",
    "                                 # 数据集的迭代次数\n",
    "                                 epochs=self.epochs,\n",
    "                                 validation_data=(x_test, y_test),\n",
    "                                 # 每多少次训练集迭代，验证一次测试集\n",
    "                                 validation_freq=self.validation_freq,\n",
    "                                 callbacks=[self.cp_callback])\n",
    "        # 输出模型各层的参数状况\n",
    "        self.model.summary()\n",
    "        # 参数提取\n",
    "        self.save_args_to_file()\n",
    "\n",
    "        # 获取模型当前loss值\n",
    "        loss = history.history['loss']\n",
    "        print(\"loss:{}\".format(loss))\n",
    "        try:\n",
    "            val_loss = history.history['val_loss']\n",
    "            print(\"val_loss:{}\".format(val_loss))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def save_args_to_file(self):\n",
    "        \"\"\"\n",
    "        参数提取，将参数保存至文件\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 指定参数存取目录\n",
    "        file_path = os.path.abspath(\n",
    "            os.path.dirname(self.__file__)) + \"\\\\weights\\\\\"\n",
    "        # 目录不存在则创建\n",
    "        if not os.path.exists(file_path):\n",
    "            os.makedirs(file_path)\n",
    "        # 打开文本文件\n",
    "        file = open(file_path + self.name + \"_weights.txt\", 'w')\n",
    "        # 将参数写入文件\n",
    "        for v in self.model.trainable_variables:\n",
    "            file.write(str(v.name) + '\\n')\n",
    "            file.write(str(v.shape) + '\\n')\n",
    "            file.write(str(v.numpy()) + '\\n')\n",
    "        file.close()\n",
    "\n",
    "    def test(self, x_test, test_set):\n",
    "        \"\"\"\n",
    "        预测测试\n",
    "        :param x_test:\n",
    "        :param test_set: 测试集\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # 测试集输入模型进行预测\n",
    "        predicted_stock_price = self.model.predict(x_test)\n",
    "        print('predicted_stock_price:',predicted_stock_price)\n",
    "        # 对预测数据还原---从（0，1）反归一化到原始范围\n",
    "        predicted_stock_price = self.fan_gui_yi(predicted_stock_price)\n",
    "\n",
    "        # 对真实数据还原---从（0，1）反归一化到原始范围\n",
    "        real_stock_price = self.fan_gui_yi(test_set[self.continuous_sample_point_num:])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(list(range(len(predicted_stock_price))), predicted_stock_price, color='b', )\n",
    "        plt.plot(list(range(len(real_stock_price))), real_stock_price, color='r')\n",
    "        plt.xlabel('time value/day', fontsize=14)\n",
    "        plt.ylabel('close value/point', fontsize=14)\n",
    "        plt.title('predict-----blue,real-----red', fontsize=10)\n",
    "        plt.show()\n",
    "        # ##########evaluate##############\n",
    "        # calculate MSE 均方误差 ---> E[(预测值-真实值)^2] (预测值减真实值求平方后求均值)\n",
    "        mse = mean_squared_error(predicted_stock_price, real_stock_price)\n",
    "        # calculate RMSE 均方根误差--->sqrt[MSE]    (对均方误差开方)\n",
    "        rmse = math.sqrt(mean_squared_error(predicted_stock_price, real_stock_price))\n",
    "        # calculate MAE 平均绝对误差----->E[|预测值-真实值|](预测值减真实值求绝对值后求均值）\n",
    "        mae = mean_absolute_error(predicted_stock_price, real_stock_price)\n",
    "        print('均方误差: %.6f' % mse)\n",
    "        print('均方根误差: %.6f' % rmse)\n",
    "        print('平均绝对误差: %.6f' % mae)\n",
    "\n",
    "    def make_x_y_train_and_test(self, data_list):\n",
    "        \"\"\"\n",
    "        制作x_train（训练集输入特征）, y_train（训练集标签）, x_test（测试集输入特征）, y_test（测试集标签）\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 获取归一化后的训练集合测试集\n",
    "        train_set, test_set = self.make_set(data_list=data_list)\n",
    "        # 初始化x_train（训练集输入特征）, y_train（训练集标签）, x_test（测试集输入特征）, y_test（测试集标签）\n",
    "        x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "        # 利用for循环，遍历整个训练集，提取训练集中连续样本为训练集输入特征和标签\n",
    "        for i in range(self.continuous_sample_point_num, len(train_set)):\n",
    "            x_train.append(train_set[i - self.continuous_sample_point_num:i, 0])\n",
    "            y_train.append(train_set[i, 0])\n",
    "        # 对训练集进行打乱\n",
    "        np.random.seed(7)\n",
    "        np.random.shuffle(x_train)\n",
    "        np.random.seed(7)\n",
    "        np.random.shuffle(y_train)\n",
    "        tf.random.set_seed(7)\n",
    "        # 将训练集由list格式变为array格式\n",
    "        x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "        # 使x_train符合RNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]。\n",
    "        x_train = self.change_data_to_rnn_input(x_train)\n",
    "        # 测试集\n",
    "        # 利用for循环，遍历整个测试集，提取训练集中连续样本为训练集输入特征和标签\n",
    "        for i in range(self.continuous_sample_point_num, len(test_set)):\n",
    "            x_test.append(test_set[i - self.continuous_sample_point_num:i, 0])\n",
    "            y_test.append(test_set[i, 0])\n",
    "        # 测试集变array并reshape为符合RNN输入要求：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]\n",
    "        x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "        print(\"x_test_shape：{}\".format(x_test.shape))\n",
    "        x_test = self.change_data_to_rnn_input(x_test)\n",
    "        return train_set, test_set, x_train, y_train, x_test, y_test\n",
    "\n",
    "    def change_data_to_rnn_input(self, data_array):\n",
    "        \"\"\"\n",
    "        将数据转变为RNN输入要求的维度\n",
    "        :param data_array:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 对输入类型进行转换\n",
    "        if isinstance(data_array, list):\n",
    "            data_array = np.array(data_array)\n",
    "        elif isinstance(data_array, np.ndarray):\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception(\"数据格式错误\")\n",
    "        rnn_input = np.reshape(data_array, (data_array.shape[0], self.continuous_sample_point_num, 1))\n",
    "        return rnn_input\n",
    "\n",
    "    def predict(self, history_data):\n",
    "        \"\"\"\n",
    "        使用模型进行预测\n",
    "        :param history_data: 历史数据list\n",
    "        :return:预测值\n",
    "        \"\"\"\n",
    "        # 将列表或数组转换为数组并提取最后一组数据\n",
    "        if isinstance(history_data, list):\n",
    "            history_data_array = history_data[self.continuous_sample_point_num * -1:]\n",
    "            history_data_array = np.array(history_data_array)\n",
    "        elif isinstance(history_data, np.ndarray):\n",
    "            history_data_array = history_data[self.continuous_sample_point_num * -1:]\n",
    "        else:\n",
    "            raise Exception(\"数据格式错误\")\n",
    "\n",
    "        # 对一维数据进行升维处理\n",
    "        if len(history_data_array.shape) == 1:\n",
    "            history_data_array = history_data_array.reshape(1, self.continuous_sample_point_num)\n",
    "\n",
    "        # 对数据形状进行效验\n",
    "        if history_data_array.shape[1] != self.continuous_sample_point_num:\n",
    "            raise Exception(\"数据形状有误\")\n",
    "\n",
    "        # 对数据进行归一化处理\n",
    "        history_data_array = history_data_array.T\n",
    "        history_data_array = self.sc.transform(history_data_array)\n",
    "        history_data_array = history_data_array.T\n",
    "\n",
    "        # 转换为RNN需要的数据形状\n",
    "        history_data_array = self.change_data_to_rnn_input(history_data_array)\n",
    "\n",
    "        # 测试集输入模型进行预测\n",
    "        predicted_stock_price = self.model.predict(history_data_array)\n",
    "        # 对预测数据还原---从（0，1）反归一化到原始范围\n",
    "        predicted_stock_price = self.fan_gui_yi(predicted_stock_price)\n",
    "        # 预测值\n",
    "        value = predicted_stock_price[-1][-1]\n",
    "        print(\"预测值：{}\".format(value))\n",
    "        return value\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sourcePath = '/Users/rumeng/Downloads/qingzang/'\n",
    "    data = []\n",
    "    select = 2 # 1股价 2数据集属性\n",
    "    stkcd = '000901'\n",
    "    city = '北京'\n",
    "    label = 'tur'\n",
    "    if select == 1:\n",
    "        with open(sourcePath+'trainSet/stock/'+stkcd+'.json', 'r',encoding='utf-8-sig') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                stkInfo = json.loads(line)\n",
    "                data.append(stkInfo[\"Clsprc\"])\n",
    "    elif select == 2:\n",
    "        dataset = pd.read_csv(sourcePath+'trainSet2/data/'+city+'.csv',on_bad_lines='skip',encoding='utf-8-sig',engine='python')\n",
    "        for i in dataset[label].values:\n",
    "            if i != -100:\n",
    "                data.append(i)\n",
    "    data_list = data \n",
    "    # 初始化模型\n",
    "    model = CgcpLSTM(name=\"股价预测\")\n",
    "    # 获取训练和测试的相关参数\n",
    "    train_set, test_set, x_train, y_train, x_test, y_test = model.make_x_y_train_and_test(data_list=data_list)\n",
    "#     print( x_train, y_train, x_test, y_test)\n",
    "    print('x_train:',x_train)\n",
    "    print('y_train:',y_train)\n",
    "    print('x_test:',x_test)\n",
    "    print('y_test:',y_test)\n",
    "    # 训练模型\n",
    "    model.train(x_train, y_train, x_test, y_test)\n",
    "    # 对模型进行测试\n",
    "    model.test(x_test, test_set)\n",
    "\n",
    "    # 利用模型进行预测\n",
    "#     history = [x for x in range(50)]\n",
    "#     model.predict(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19679a34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T01:50:40.245878Z",
     "start_time": "2022-07-25T01:50:37.540481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 14ms/step\n",
      "predicted_stock_price: [[0.09191322]\n",
      " [0.09168647]\n",
      " [0.09017564]\n",
      " [0.0900747 ]\n",
      " [0.09036043]\n",
      " [0.09002559]\n",
      " [0.08976001]\n",
      " [0.08823967]\n",
      " [0.0892566 ]\n",
      " [0.08911836]\n",
      " [0.08925967]\n",
      " [0.08991924]\n",
      " [0.08829851]\n",
      " [0.08941849]\n",
      " [0.09056306]\n",
      " [0.09157555]\n",
      " [0.09190066]\n",
      " [0.09187637]\n",
      " [0.0914029 ]\n",
      " [0.09067473]\n",
      " [0.09188016]\n",
      " [0.09476668]\n",
      " [0.09720764]\n",
      " [0.09792343]\n",
      " [0.10109577]\n",
      " [0.1018097 ]\n",
      " [0.10152741]\n",
      " [0.09989589]\n",
      " [0.10069036]\n",
      " [0.09989557]\n",
      " [0.09782641]\n",
      " [0.09814517]\n",
      " [0.09810813]\n",
      " [0.09894659]\n",
      " [0.10186082]\n",
      " [0.09906638]\n",
      " [0.09656961]\n",
      " [0.09571894]\n",
      " [0.09245853]\n",
      " [0.0918992 ]\n",
      " [0.09091979]\n",
      " [0.08886768]\n",
      " [0.08960231]\n",
      " [0.08941935]\n",
      " [0.08805434]\n",
      " [0.08862637]\n",
      " [0.0879339 ]\n",
      " [0.0873356 ]\n",
      " [0.08769308]\n",
      " [0.08824755]\n",
      " [0.08965056]\n",
      " [0.0899186 ]\n",
      " [0.09012826]\n",
      " [0.08931901]\n",
      " [0.08963202]\n",
      " [0.08979012]\n",
      " [0.08964993]\n",
      " [0.08987612]\n",
      " [0.09016629]\n",
      " [0.08980159]\n",
      " [0.08993512]\n",
      " [0.09040415]\n",
      " [0.09070431]\n",
      " [0.09158677]\n",
      " [0.09171975]\n",
      " [0.09275265]\n",
      " [0.09270534]\n",
      " [0.09412682]\n",
      " [0.09288533]\n",
      " [0.09364076]\n",
      " [0.09364024]\n",
      " [0.09362011]\n",
      " [0.09384005]\n",
      " [0.09431396]\n",
      " [0.09610946]\n",
      " [0.09619638]\n",
      " [0.09716006]\n",
      " [0.09750979]\n",
      " [0.09599359]\n",
      " [0.09931922]\n",
      " [0.10023786]\n",
      " [0.10023721]\n",
      " [0.09885614]\n",
      " [0.09835456]\n",
      " [0.09683378]\n",
      " [0.09767997]\n",
      " [0.0981621 ]\n",
      " [0.09693566]\n",
      " [0.09600009]\n",
      " [0.09692521]\n",
      " [0.09712826]\n",
      " [0.09644704]\n",
      " [0.09540288]\n",
      " [0.09563522]\n",
      " [0.09658925]\n",
      " [0.09675966]\n",
      " [0.09759288]\n",
      " [0.09858228]\n",
      " [0.09419762]\n",
      " [0.09202377]\n",
      " [0.09165899]\n",
      " [0.09008808]\n",
      " [0.09073845]\n",
      " [0.09076582]\n",
      " [0.08965874]\n",
      " [0.08898057]\n",
      " [0.08866267]\n",
      " [0.08797956]\n",
      " [0.08979024]\n",
      " [0.09104046]\n",
      " [0.09096797]\n",
      " [0.09086463]\n",
      " [0.09040986]\n",
      " [0.08971252]\n",
      " [0.08901465]\n",
      " [0.08898565]\n",
      " [0.08823337]\n",
      " [0.08858056]\n",
      " [0.08764218]\n",
      " [0.08445635]\n",
      " [0.08410154]\n",
      " [0.08529659]\n",
      " [0.08472931]\n",
      " [0.0860465 ]\n",
      " [0.08607921]\n",
      " [0.08554517]\n",
      " [0.08582975]\n",
      " [0.0848314 ]\n",
      " [0.08400017]\n",
      " [0.08029348]\n",
      " [0.0773132 ]\n",
      " [0.07572746]\n",
      " [0.07718278]\n",
      " [0.07828708]\n",
      " [0.07907964]\n",
      " [0.08340402]\n",
      " [0.08327068]\n",
      " [0.08249347]\n",
      " [0.08077657]\n",
      " [0.07962517]\n",
      " [0.07871377]\n",
      " [0.07849942]\n",
      " [0.08096729]\n",
      " [0.0819758 ]\n",
      " [0.08827892]\n",
      " [0.08940889]\n",
      " [0.09135601]\n",
      " [0.09134839]\n",
      " [0.09076649]\n",
      " [0.08764957]\n",
      " [0.08733542]\n",
      " [0.08945692]\n",
      " [0.08998175]\n",
      " [0.09042497]\n",
      " [0.08958073]\n",
      " [0.08955999]\n",
      " [0.08869083]\n",
      " [0.08762611]\n",
      " [0.08699594]\n",
      " [0.08925813]\n",
      " [0.08948351]\n",
      " [0.08999334]\n",
      " [0.09215346]\n",
      " [0.09248149]\n",
      " [0.09347536]\n",
      " [0.0949048 ]\n",
      " [0.09662966]\n",
      " [0.09688516]\n",
      " [0.09598364]\n",
      " [0.09600824]\n",
      " [0.0947976 ]\n",
      " [0.09525795]\n",
      " [0.09609063]\n",
      " [0.09775086]\n",
      " [0.10057802]\n",
      " [0.11522026]\n",
      " [0.11955739]\n",
      " [0.13156357]\n",
      " [0.13312203]\n",
      " [0.1306974 ]\n",
      " [0.13527381]\n",
      " [0.13710204]\n",
      " [0.1348003 ]\n",
      " [0.13271055]\n",
      " [0.13384774]\n",
      " [0.13531698]\n",
      " [0.12992051]\n",
      " [0.12557907]\n",
      " [0.12815407]\n",
      " [0.12718433]\n",
      " [0.13476825]\n",
      " [0.13823736]\n",
      " [0.13515571]\n",
      " [0.1375976 ]\n",
      " [0.13421668]\n",
      " [0.13458733]\n",
      " [0.12787941]\n",
      " [0.12444712]\n",
      " [0.11135038]\n",
      " [0.11361705]\n",
      " [0.11680569]\n",
      " [0.11808923]\n",
      " [0.11980818]\n",
      " [0.12026151]\n",
      " [0.12047671]\n",
      " [0.12444687]\n",
      " [0.13045824]\n",
      " [0.1319148 ]\n",
      " [0.13576566]\n",
      " [0.14154536]\n",
      " [0.14939645]\n",
      " [0.14530143]\n",
      " [0.14109126]\n",
      " [0.13911696]\n",
      " [0.15029569]\n",
      " [0.15072095]\n",
      " [0.15171728]\n",
      " [0.14604878]\n",
      " [0.14598954]\n",
      " [0.14374176]\n",
      " [0.14685152]\n",
      " [0.14501777]\n",
      " [0.14211059]\n",
      " [0.1408929 ]\n",
      " [0.13983417]\n",
      " [0.13704671]\n",
      " [0.14004555]\n",
      " [0.14431287]\n",
      " [0.14440921]\n",
      " [0.14087409]\n",
      " [0.1349689 ]\n",
      " [0.13148943]\n",
      " [0.13016304]\n",
      " [0.13524127]\n",
      " [0.14044666]\n",
      " [0.14481202]\n",
      " [0.14649193]\n",
      " [0.14683472]\n",
      " [0.14257005]\n",
      " [0.1468306 ]\n",
      " [0.14607032]\n",
      " [0.14984387]\n",
      " [0.14924657]\n",
      " [0.14578724]\n",
      " [0.13894896]\n",
      " [0.14232503]\n",
      " [0.14069094]\n",
      " [0.13843873]\n",
      " [0.14635658]\n",
      " [0.14768836]\n",
      " [0.14701316]\n",
      " [0.14356129]\n",
      " [0.1459057 ]\n",
      " [0.14315656]\n",
      " [0.14028074]\n",
      " [0.15392211]\n",
      " [0.16091648]\n",
      " [0.16586195]\n",
      " [0.16546822]\n",
      " [0.17820221]\n",
      " [0.18113306]\n",
      " [0.18006855]\n",
      " [0.18413046]\n",
      " [0.18656152]\n",
      " [0.21054316]\n",
      " [0.21815899]\n",
      " [0.23283075]\n",
      " [0.21745053]\n",
      " [0.21951064]\n",
      " [0.2061321 ]\n",
      " [0.19953299]\n",
      " [0.20183274]\n",
      " [0.19299185]\n",
      " [0.18340984]\n",
      " [0.18863209]\n",
      " [0.18953414]\n",
      " [0.1844341 ]\n",
      " [0.17771208]\n",
      " [0.18213053]\n",
      " [0.19179122]\n",
      " [0.18233582]\n",
      " [0.18280923]\n",
      " [0.18010177]\n",
      " [0.17365594]\n",
      " [0.1736365 ]\n",
      " [0.18576503]\n",
      " [0.18740547]\n",
      " [0.19349742]\n",
      " [0.1937451 ]\n",
      " [0.18757889]\n",
      " [0.19565487]\n",
      " [0.18896261]\n",
      " [0.1861943 ]\n",
      " [0.18801539]\n",
      " [0.19737045]\n",
      " [0.19062471]\n",
      " [0.1875824 ]\n",
      " [0.188269  ]\n",
      " [0.18105158]\n",
      " [0.18266873]\n",
      " [0.19170704]\n",
      " [0.19144757]\n",
      " [0.19430321]\n",
      " [0.20879434]\n",
      " [0.21048363]\n",
      " [0.21084502]\n",
      " [0.22146592]\n",
      " [0.2245841 ]\n",
      " [0.21686974]\n",
      " [0.22043434]\n",
      " [0.22100529]\n",
      " [0.21157071]\n",
      " [0.20712042]\n",
      " [0.20004037]\n",
      " [0.19739614]\n",
      " [0.20610335]\n",
      " [0.20688924]\n",
      " [0.20697017]\n",
      " [0.21754621]\n",
      " [0.206409  ]\n",
      " [0.18074125]\n",
      " [0.1687353 ]\n",
      " [0.14949438]\n",
      " [0.14806661]\n",
      " [0.15386727]\n",
      " [0.15647933]\n",
      " [0.16662976]\n",
      " [0.17096356]\n",
      " [0.17120345]\n",
      " [0.16300273]\n",
      " [0.15652394]\n",
      " [0.15569279]\n",
      " [0.15425791]\n",
      " [0.15256275]\n",
      " [0.157953  ]\n",
      " [0.1580977 ]\n",
      " [0.15942957]\n",
      " [0.15926369]\n",
      " [0.15797827]\n",
      " [0.15761198]\n",
      " [0.15543993]\n",
      " [0.15057868]\n",
      " [0.14835428]\n",
      " [0.15239072]\n",
      " [0.15302677]\n",
      " [0.15475114]\n",
      " [0.14973238]\n",
      " [0.14185762]\n",
      " [0.13187051]\n",
      " [0.13082379]\n",
      " [0.13021   ]\n",
      " [0.13382202]\n",
      " [0.13123414]\n",
      " [0.12641016]\n",
      " [0.12230278]\n",
      " [0.12848008]\n",
      " [0.1330621 ]\n",
      " [0.14232078]\n",
      " [0.15251932]\n",
      " [0.14690578]\n",
      " [0.1465218 ]\n",
      " [0.1364541 ]\n",
      " [0.13741162]\n",
      " [0.14468487]\n",
      " [0.14561707]\n",
      " [0.14305414]\n",
      " [0.14733303]\n",
      " [0.1544021 ]\n",
      " [0.15137315]\n",
      " [0.14479165]\n",
      " [0.13130988]\n",
      " [0.12993228]\n",
      " [0.1276466 ]\n",
      " [0.12601644]\n",
      " [0.12867631]\n",
      " [0.13348167]\n",
      " [0.13315773]\n",
      " [0.13353828]\n",
      " [0.13342023]\n",
      " [0.13696472]\n",
      " [0.13625629]\n",
      " [0.13122283]\n",
      " [0.12870069]\n",
      " [0.13168253]\n",
      " [0.13232136]\n",
      " [0.1305128 ]\n",
      " [0.12569463]\n",
      " [0.12412804]\n",
      " [0.12371513]\n",
      " [0.1238001 ]\n",
      " [0.11929108]\n",
      " [0.111976  ]\n",
      " [0.11297198]\n",
      " [0.11375814]\n",
      " [0.11564833]\n",
      " [0.11571057]\n",
      " [0.11295976]\n",
      " [0.11735626]\n",
      " [0.1128713 ]\n",
      " [0.11018203]\n",
      " [0.11038812]\n",
      " [0.10832231]\n",
      " [0.11066592]\n",
      " [0.11347046]\n",
      " [0.10748039]\n",
      " [0.10710894]\n",
      " [0.10626787]\n",
      " [0.10601608]\n",
      " [0.0977073 ]\n",
      " [0.09405982]\n",
      " [0.08807854]\n",
      " [0.0836013 ]\n",
      " [0.08681656]\n",
      " [0.07752173]\n",
      " [0.07679665]\n",
      " [0.07585587]\n",
      " [0.07551652]\n",
      " [0.07679343]\n",
      " [0.0849672 ]\n",
      " [0.08537635]\n",
      " [0.08066271]\n",
      " [0.08179073]\n",
      " [0.08238588]\n",
      " [0.07947493]\n",
      " [0.07886127]\n",
      " [0.07869256]\n",
      " [0.07954958]\n",
      " [0.08804294]\n",
      " [0.09636737]\n",
      " [0.0970078 ]\n",
      " [0.09606726]\n",
      " [0.09288998]\n",
      " [0.09233445]\n",
      " [0.09548886]\n",
      " [0.09691589]\n",
      " [0.0913118 ]\n",
      " [0.085655  ]\n",
      " [0.08421527]\n",
      " [0.08499645]\n",
      " [0.09024012]\n",
      " [0.08858655]\n",
      " [0.09297369]\n",
      " [0.09239793]\n",
      " [0.08801556]\n",
      " [0.08598235]\n",
      " [0.08130604]\n",
      " [0.08036467]\n",
      " [0.08122377]\n",
      " [0.08566558]\n",
      " [0.09147471]\n",
      " [0.09358372]\n",
      " [0.09502746]\n",
      " [0.10949527]\n",
      " [0.12065598]\n",
      " [0.11881504]\n",
      " [0.11731645]\n",
      " [0.11378643]\n",
      " [0.11357836]\n",
      " [0.11526896]\n",
      " [0.12104882]\n",
      " [0.11393896]\n",
      " [0.1106427 ]\n",
      " [0.11114445]\n",
      " [0.10856878]\n",
      " [0.10863975]\n",
      " [0.10796407]\n",
      " [0.10937265]\n",
      " [0.10686775]\n",
      " [0.10291333]\n",
      " [0.11056168]\n",
      " [0.11554468]\n",
      " [0.11578306]\n",
      " [0.12498754]\n",
      " [0.12390281]\n",
      " [0.12670672]\n",
      " [0.1278521 ]\n",
      " [0.13471976]\n",
      " [0.12296934]\n",
      " [0.12305725]\n",
      " [0.12134688]\n",
      " [0.10856719]\n",
      " [0.11590889]\n",
      " [0.11385328]\n",
      " [0.11878403]\n",
      " [0.11870237]\n",
      " [0.11302833]\n",
      " [0.12624522]\n",
      " [0.137126  ]\n",
      " [0.1315037 ]\n",
      " [0.13413088]\n",
      " [0.140079  ]\n",
      " [0.13865997]\n",
      " [0.12899989]\n",
      " [0.13074076]\n",
      " [0.1319251 ]\n",
      " [0.13061139]\n",
      " [0.13610226]\n",
      " [0.13336512]\n",
      " [0.1308242 ]\n",
      " [0.12967046]\n",
      " [0.13117228]\n",
      " [0.12407808]\n",
      " [0.12289025]\n",
      " [0.12252016]\n",
      " [0.12037119]\n",
      " [0.12386256]\n",
      " [0.12347985]\n",
      " [0.12929967]\n",
      " [0.12416103]\n",
      " [0.12379581]\n",
      " [0.1226331 ]\n",
      " [0.11757005]\n",
      " [0.11723126]\n",
      " [0.11408447]\n",
      " [0.11583456]\n",
      " [0.11465286]\n",
      " [0.11787367]\n",
      " [0.12345433]\n",
      " [0.12422808]\n",
      " [0.12096222]\n",
      " [0.11592157]\n",
      " [0.11580153]\n",
      " [0.11377847]\n",
      " [0.11489055]\n",
      " [0.11551441]\n",
      " [0.11889113]\n",
      " [0.11470934]\n",
      " [0.11636019]\n",
      " [0.11313317]\n",
      " [0.10861887]\n",
      " [0.10302135]\n",
      " [0.09668805]\n",
      " [0.09525333]\n",
      " [0.0937195 ]\n",
      " [0.09273994]\n",
      " [0.09219216]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tpredicted_stock_price' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mCgcpLSTM.test\u001b[0;34m(self, x_test, test_set)\u001b[0m\n\u001b[1;32m    193\u001b[0m real_stock_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfan_gui_yi(test_set[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_sample_point_num:])\n\u001b[1;32m    195\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m--> 196\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtpredicted_stock_price\u001b[49m))), predicted_stock_price, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, )\n\u001b[1;32m    197\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(real_stock_price))), real_stock_price, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    198\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime value/day\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tpredicted_stock_price' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.test(x_test, test_set)\n",
    "\n",
    "\n",
    "# history = [x for x in range(50)]\n",
    "# model.predict(history)\n",
    "\n",
    "# test_predict = []\n",
    "# for step in range(len(x_test) - 1):\n",
    "#     predict1 = model.predict(x_test[step])\n",
    "# #     predict = model.run(pred, feed_dict={X: [x_test[step]], keep_prob: 1})\n",
    "#     predict1 = predict1.reshape((-1))\n",
    "#     print(predict1)\n",
    "#     test_predict.extend(predict1)  # 把predict的内容添加到列表\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(list(range(len(test_predict))), test_predict, color='b', )\n",
    "# plt.plot(list(range(len(test_y))), test_y, color='r')\n",
    "# plt.xlabel('time value/day', fontsize=14)\n",
    "# plt.ylabel('close value/point', fontsize=14)\n",
    "# plt.title('predict-----blue,real-----red', fontsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cfdcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21f17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
